{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":117682,"databundleVersionId":15062069,"sourceType":"competition"},{"sourceId":14297474,"sourceType":"datasetVersion","datasetId":9126617},{"sourceId":288572598,"sourceType":"kernelVersion"},{"sourceId":290917305,"sourceType":"kernelVersion"},{"sourceId":655294,"sourceType":"modelInstanceVersion","modelInstanceId":495238,"modelId":510647},{"sourceId":660383,"sourceType":"modelInstanceVersion","modelInstanceId":499479,"modelId":510647},{"sourceId":665589,"sourceType":"modelInstanceVersion","modelInstanceId":503784,"modelId":510647},{"sourceId":665924,"sourceType":"modelInstanceVersion","modelInstanceId":504051,"modelId":510647},{"sourceId":672178,"sourceType":"modelInstanceVersion","modelInstanceId":495238,"modelId":510647},{"sourceId":673516,"sourceType":"modelInstanceVersion","modelInstanceId":499479,"modelId":510647},{"sourceId":674747,"sourceType":"modelInstanceVersion","modelInstanceId":503784,"modelId":510647},{"sourceId":681152,"sourceType":"modelInstanceVersion","modelInstanceId":516822,"modelId":510647},{"sourceId":694469,"sourceType":"modelInstanceVersion","modelInstanceId":522802,"modelId":536801},{"sourceId":697465,"sourceType":"modelInstanceVersion","modelInstanceId":522802,"modelId":536801}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training Notebooks\n\n- [Vesuvius Surface 3D Detection in Keras-JAX](https://www.kaggle.com/code/ipythonx/vesuvius-surface-3d-detection-in-jax)\n- [Vesuvius Surface 3D Detection in PyTorch](https://www.kaggle.com/code/ipythonx/vesuvius-surface-3d-detection-in-pytorch)\n- [Vesuvius Surface 3D Detection in PyTorch Lightning](https://www.kaggle.com/code/ipythonx/train-vesuvius-surface-3d-detection-in-lightning)\n- [[WIP] Vesuvius Surface 2.5D Detection](https://www.kaggle.com/code/ipythonx/wip-vesuvius-surface-2-5d-detection)\n\n**Note**\n1. The inference code below is adapted from the **Keras-JAX** version. The PyTorch and Lightning implementations follow the same workflow. Training was performed on a single Tesla T4 (16 GB VRAM) with extended epochs.\n2. Both the training and inference pipelines are implemented using [`medicai`](https://github.com/innat/medic-ai), a **Keras 3** based multi-backend medical ML library designed for 2D and 3D classification and segmentation tasks. However, please note, `medicai` project is still new and actively evolving.","metadata":{}},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"var=\"/kaggle/input/vsdetection-packages-offline-installer-only/whls\"\n!pip install \\\n    \"$var\"/keras_nightly-3.12.0.dev2025100703-py3-none-any.whl \\\n    \"$var\"/tifffile-2025.12.12-py3-none-any.whl \\\n    \"$var\"/imagecodecs-2025.11.11-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl \\\n    \"$var\"/medicai-0.0.3-py3-none-any.whl \\\n    --no-index \\\n    --find-links \"$var\"","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-12-23T19:34:38.386605Z","iopub.execute_input":"2025-12-23T19:34:38.387158Z","iopub.status.idle":"2025-12-23T19:34:46.229044Z","shell.execute_reply.started":"2025-12-23T19:34:38.387129Z","shell.execute_reply":"2025-12-23T19:34:46.228381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Protobuf compatibility patch (for old code using MessageFactory.GetPrototype) ---\n\ntry:\n    from google.protobuf import message_factory as _message_factory\n\n    # Only patch if the method is missing (protobuf >= 5)\n    if not hasattr(_message_factory.MessageFactory, \"GetPrototype\"):\n        from google.protobuf.message_factory import GetMessageClass\n\n        def _GetPrototype(self, descriptor):\n            # Old API used MessageFactory().GetPrototype(descriptor)\n            # New API is GetMessageClass(descriptor). We just bridge them.\n            return GetMessageClass(descriptor)\n\n        _message_factory.MessageFactory.GetPrototype = _GetPrototype\n        print(\"Patched protobuf: added MessageFactory.GetPrototype\")\n    else:\n        print(\"protobuf already has MessageFactory.GetPrototype; no patch needed.\")\nexcept Exception as e:\n    print(\"Could not patch protobuf MessageFactory:\", e)\n\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\n\nimport keras\nfrom medicai.transforms import (\n    Compose,\n    ScaleIntensityRange,\n)\nfrom medicai.models import SegFormer, TransUNet\nfrom medicai.utils.inference import SlidingWindowInference\n\nimport numpy as np\nimport pandas as pd\nimport zipfile\nimport tifffile\nfrom matplotlib import pyplot as plt\n\nkeras.config.backend(), keras.version()","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-12-23T19:34:46.23085Z","iopub.execute_input":"2025-12-23T19:34:46.231146Z","iopub.status.idle":"2025-12-23T19:35:02.559183Z","shell.execute_reply.started":"2025-12-23T19:34:46.231111Z","shell.execute_reply":"2025-12-23T19:35:02.558526Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Dataset**","metadata":{}},{"cell_type":"code","source":"root_dir = \"/kaggle/input/vesuvius-challenge-surface-detection\"\ntest_dir = f\"{root_dir}/test_images\"\noutput_dir = \"/kaggle/working/submission_masks\"\nzip_path = \"/kaggle/working/submission.zip\"\nos.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:02.559987Z","iopub.execute_input":"2025-12-23T19:35:02.560527Z","iopub.status.idle":"2025-12-23T19:35:02.565081Z","shell.execute_reply.started":"2025-12-23T19:35:02.560504Z","shell.execute_reply":"2025-12-23T19:35:02.564245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(f\"{root_dir}/test.csv\")\ntest_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:02.568099Z","iopub.execute_input":"2025-12-23T19:35:02.568707Z","iopub.status.idle":"2025-12-23T19:35:02.680682Z","shell.execute_reply.started":"2025-12-23T19:35:02.568674Z","shell.execute_reply":"2025-12-23T19:35:02.680037Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Transformation**","metadata":{}},{"cell_type":"code","source":"def val_transformation(image):\n    data = {\"image\": image}\n    pipeline = Compose([\n        ScaleIntensityRange(\n            keys=[\"image\"],\n            a_min = 0,\n            a_max = 255,\n            b_min = 0,\n            b_max = 1,\n            clip = True,\n        ),\n    ])\n    result = pipeline(data)\n    return result[\"image\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:02.681415Z","iopub.execute_input":"2025-12-23T19:35:02.681688Z","iopub.status.idle":"2025-12-23T19:35:02.686063Z","shell.execute_reply.started":"2025-12-23T19:35:02.681658Z","shell.execute_reply":"2025-12-23T19:35:02.685324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Model**","metadata":{}},{"cell_type":"code","source":"num_classes=3\n\ndef get_model():\n    ## LB: 0.486\n    # model = SegFormer(\n    #     input_shape=(128, 128, 128, 1),\n    #     encoder_name='mit_b2',\n    #     classifier_activation='softmax',\n    #     num_classes=num_classes,\n    # )\n    # model.load_weights(\n    #     \"/kaggle/input/vsd-model/keras/segformer.mit.b2/2/segformer.mit.b2.weights.h5\"\n    # )\n\n    ## LB: 0.5 \n    model = TransUNet(\n        input_shape=(160, 160, 160, 1),\n        encoder_name='seresnext50',\n        classifier_activation='softmax',\n        num_classes=num_classes,\n    )\n    model.load_weights(\n        \"/kaggle/input/train-vesuvius-surface-3d-detection-on-tpu/model.weights.h5\"\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:02.687008Z","iopub.execute_input":"2025-12-23T19:35:02.687308Z","iopub.status.idle":"2025-12-23T19:35:02.700217Z","shell.execute_reply.started":"2025-12-23T19:35:02.687283Z","shell.execute_reply":"2025-12-23T19:35:02.699366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = get_model()\nmodel.count_params() / 1e6\n# predictor = tf.function(model, jit_compile=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:02.700924Z","iopub.execute_input":"2025-12-23T19:35:02.701137Z","iopub.status.idle":"2025-12-23T19:35:21.585687Z","shell.execute_reply.started":"2025-12-23T19:35:02.701112Z","shell.execute_reply":"2025-12-23T19:35:21.585092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.instance_describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:21.586395Z","iopub.execute_input":"2025-12-23T19:35:21.58665Z","iopub.status.idle":"2025-12-23T19:35:21.647344Z","shell.execute_reply.started":"2025-12-23T19:35:21.586632Z","shell.execute_reply":"2025-12-23T19:35:21.646708Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Sliding Window Inference**","metadata":{}},{"cell_type":"code","source":"pred = SlidingWindowInference(\n    model,\n    roi_size=(160,160,160),\n    num_classes = 3,\n    mode=\"gaussian\",\n    overlap=0.50,\n    sw_batch_size = 1\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:21.64808Z","iopub.execute_input":"2025-12-23T19:35:21.648663Z","iopub.status.idle":"2025-12-23T19:35:21.920044Z","shell.execute_reply.started":"2025-12-23T19:35:21.648642Z","shell.execute_reply":"2025-12-23T19:35:21.919223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport tifffile\nimport scipy.ndimage as ndi\nfrom skimage.morphology import remove_small_objects\n\n\ndef load_volume(path):\n    vol = tifffile.imread(path)          # (D, H, W)\n    vol = vol.astype(np.float32)\n    vol = vol[None, ..., None]           # (1, D, H, W, 1)\n    return vol\n\n\n# ==========================================\n# ROTATION TTA HELPERS (CLOCKWISE)\n# ==========================================\ndef rot90_volume(vol, k):\n    \"\"\"\n    Rotate volume k times 90° clockwise in HW plane.\n    vol:\n      (1, D, H, W, 1) OR (D, H, W)\n    \"\"\"\n    if vol.ndim == 5:\n        return np.rot90(vol, k=-k, axes=(2, 3))\n    else:\n        return np.rot90(vol, k=-k, axes=(1, 2))\n\n\ndef unrot90_volume(vol, k):\n    return rot90_volume(vol, (4 - k) % 4)\n\n\ndef predict_probs_tta_rot(sample):\n    \"\"\"\n    4x rotation TTA: 0°, 90°, 180°, 270°\n    sample: (1, D, H, W, 1)\n    returns: averaged probs (D, H, W)\n    \"\"\"\n    probs_accum = []\n\n    for k in range(4):\n        s_rot = rot90_volume(sample, k)\n\n        out = pred(s_rot)              # (1, D, H, W, 2)\n        out = np.asarray(out)\n        probs = out[0, ..., 1]         # (D, H, W)\n\n        probs = unrot90_volume(probs, k)\n        probs_accum.append(probs)\n\n    return np.mean(probs_accum, axis=0)\n\n\n# ==========================================\n# HELPER: Anisotropic Structure Builder\n# ==========================================\ndef build_anisotropic_struct(z_radius: int, xy_radius: int):\n    z, r = z_radius, xy_radius\n\n    if z == 0 and r == 0:\n        return None\n\n    if z == 0 and r > 0:\n        size = 2 * r + 1\n        struct = np.zeros((1, size, size), dtype=bool)\n        cy, cx = r, r\n        for dy in range(-r, r + 1):\n            for dx in range(-r, r + 1):\n                if dy * dy + dx * dx <= r * r:\n                    struct[0, cy + dy, cx + dx] = True\n        return struct\n\n    if z > 0 and r == 0:\n        struct = np.zeros((2 * z + 1, 1, 1), dtype=bool)\n        struct[:, 0, 0] = True\n        return struct\n\n    depth = 2 * z + 1\n    size = 2 * r + 1\n    struct = np.zeros((depth, size, size), dtype=bool)\n    cz, cy, cx = z, r, r\n    for dz in range(-z, z + 1):\n        for dy in range(-r, r + 1):\n            for dx in range(-r, r + 1):\n                if dy * dy + dx * dx <= r * r:\n                    struct[cz + dz, cy + dy, cx + dx] = True\n    return struct\n\n\n# ==========================================\n# MAIN POST-PROCESSING LOGIC\n# ==========================================\ndef topo_postprocess(\n    probs,          # (D, H, W)\n    T_low=0.90,\n    T_high=0.90,\n    z_radius=1,\n    xy_radius=0,\n    dust_min_size=100,\n):\n    # --- Step 1: 3D Hysteresis ---\n    strong = probs >= T_high\n    weak   = probs >= T_low\n\n    if not strong.any():\n        return np.zeros_like(probs, dtype=np.uint8)\n\n    struct_hyst = ndi.generate_binary_structure(3, 3)\n    mask = ndi.binary_propagation(strong, mask=weak, structure=struct_hyst)\n\n    if not mask.any():\n        return np.zeros_like(probs, dtype=np.uint8)\n\n    # --- Step 2: 3D Anisotropic Closing ---\n    if z_radius > 0 or xy_radius > 0:\n        struct_close = build_anisotropic_struct(z_radius, xy_radius)\n        if struct_close is not None:\n            mask = ndi.binary_closing(mask, structure=struct_close)\n\n    # --- Step 3: Dust Removal ---\n    if dust_min_size > 0:\n        mask = remove_small_objects(mask.astype(bool), min_size=dust_min_size)\n\n    return mask.astype(np.uint8)\n\n\n# ==========================================\n# PREDICT (WITH ROTATION TTA)\n# ==========================================\ndef predict(\n    sample,\n    iid=None,\n    T_low=0.50,\n    T_high=0.90,\n    z_radius=1,\n    xy_radius=0,\n    dust_min_size=100,\n):\n    \"\"\"\n    sample: (1, D, H, W, 1)\n    \"\"\"\n\n    # --------- ROTATION TTA PROBS ---------\n    probs_fg = predict_probs_tta_rot(sample)   # (D, H, W)\n\n    if iid is not None:\n        np.save(iid, probs_fg)\n\n    # --------- POSTPROCESS (UNCHANGED) ----\n    final = topo_postprocess(\n        probs_fg,\n        T_low=T_low,\n        T_high=T_high,\n        z_radius=z_radius,\n        xy_radius=xy_radius,\n        dust_min_size=dust_min_size,\n    )\n\n    return final  # (D, H, W) uint8 {0,1}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:21.922426Z","iopub.execute_input":"2025-12-23T19:35:21.922922Z","iopub.status.idle":"2025-12-23T19:35:22.071782Z","shell.execute_reply.started":"2025-12-23T19:35:21.922901Z","shell.execute_reply":"2025-12-23T19:35:22.07123Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Prediction and Zip Submission**","metadata":{}},{"cell_type":"code","source":"testing = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:22.07248Z","iopub.execute_input":"2025-12-23T19:35:22.072993Z","iopub.status.idle":"2025-12-23T19:35:22.076697Z","shell.execute_reply.started":"2025-12-23T19:35:22.072974Z","shell.execute_reply":"2025-12-23T19:35:22.07598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if testing:\n    \n    test_dir = \"/kaggle/input/vesuvius-challenge-surface-detection/train_images\"\n    test_df = pd.read_csv(f\"{root_dir}/train.csv\")\n    test_ids = {956073442, 961304774,969293709,975031774,985841575,992852942}\n    test_df = (\n        test_df\n        .loc[test_df[\"id\"].isin(test_ids)]\n        .reset_index(drop=True)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:22.077467Z","iopub.execute_input":"2025-12-23T19:35:22.077725Z","iopub.status.idle":"2025-12-23T19:35:22.104421Z","shell.execute_reply.started":"2025-12-23T19:35:22.077703Z","shell.execute_reply":"2025-12-23T19:35:22.103655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with zipfile.ZipFile(\n    zip_path, \"w\", compression=zipfile.ZIP_DEFLATED\n) as z:\n    for image_id in test_df[\"id\"]:\n        tif_path = f\"{test_dir}/{image_id}.tif\"\n            \n        volume = load_volume(tif_path)\n        volume = val_transformation(volume)\n        if testing :\n            output = predict(volume,f\"{image_id}\") \n        else :\n            output = predict(volume)\n        \n        out_path = f\"{output_dir}/{image_id}.tif\"\n        tifffile.imwrite(out_path, output.astype(np.uint8))\n\n        z.write(out_path, arcname=f\"{image_id}.tif\")\n        os.remove(out_path)\n\nprint(\"Submission ZIP:\", zip_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T19:35:22.105322Z","iopub.execute_input":"2025-12-23T19:35:22.105568Z","iopub.status.idle":"2025-12-23T19:38:08.444178Z","shell.execute_reply.started":"2025-12-23T19:35:22.105545Z","shell.execute_reply":"2025-12-23T19:38:08.443516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}