# Commands to run on OSCER cluster

# 1. First, run the validation sweep:
cd /scratch/jowny/vesuvius/vesuviusChallenge/vesuvius-competition
export PYTHONPATH=$PWD:$PWD/src
source venv/bin/activate

python scripts/local_val_sweep.py \
    --model-path models/from_modal/surface_unet3d_tuned_epoch15.pth \
    --config-path configs/experiments/surface_unet3d_tuned.yaml \
    --max-volumes 2 \
    --t-low-values "0.28,0.30,0.32,0.34,0.36,0.38" \
    --t-high-values "0.82,0.84,0.86,0.88" \
    --dust-values "50,100" \
    --no-tta

# 2. Then inspect the failing volume:
python << 'EOF'
import numpy as np
import torch
from pathlib import Path
import sys
sys.path.append('.')

from train import load_config
from src.inference.predict import VesuviusPredictor3D
from src.inference.create_submission import topo_postprocess
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# Setup
model_path = "models/from_modal/surface_unet3d_tuned_epoch15.pth"
config_path = "configs/experiments/surface_unet3d_tuned.yaml"
vid = "419698042"

cfg = load_config(config_path)
predictor = VesuviusPredictor3D(
    model_path=model_path,
    device="cuda" if torch.cuda.is_available() else "cpu",
    roi_size=tuple(cfg["data"]["patch_size"]),
    overlap=0.5,
    class_index=1,
    config_path=config_path,
)

# Load volume
vol_path = Path("data/processed_3d/images/volume_" + vid + ".npz")
mask_path = Path("data/processed_3d/masks/mask_" + vid + ".npz")
volume = np.load(vol_path)["data"]
mask = np.load(mask_path)["data"]
gt = (mask == 1).astype(np.uint8)

print(f"\nVolume {vid} shape: {volume.shape}")
print(f"Volume stats - min: {volume.min():.3f}, max: {volume.max():.3f}, mean: {volume.mean():.3f}")

# Predict
print("\nRunning prediction...")
probs = predictor.predict_volume(volume)
print(f"Prob stats - min: {probs.min():.3f}, max: {probs.max():.3f}, mean: {probs.mean():.3f}")

# Apply post-processing
pred = topo_postprocess(probs, t_low=0.35, t_high=0.85, z_radius=1, xy_radius=0, dust_min_size=50)
print(f"Pred binary - sum: {pred.sum()}, frac: {pred.mean():.4f}")
print(f"GT binary - sum: {gt.sum()}, frac: {gt.mean():.4f}")

# Save a middle slice visualization
mid_z = volume.shape[0] // 2
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
axes[0].imshow(probs[mid_z], cmap='viridis', vmin=0, vmax=1)
axes[0].set_title(f'Probabilities (z={mid_z})')
axes[1].imshow(pred[mid_z], cmap='gray')
axes[1].set_title('Predictions')
axes[2].imshow(gt[mid_z], cmap='gray') 
axes[2].set_title('Ground Truth')
plt.tight_layout()
plt.savefig(f'volume_{vid}_slice.png')
print(f"Saved visualization to volume_{vid}_slice.png")
EOF

# 3. Create and submit the 60-epoch training job:
cat > train_60epoch.sbatch << 'EOF'
#!/bin/bash
#SBATCH -p gpu
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --constraint=a100
#SBATCH --time=24:00:00
#SBATCH --mem=64G
#SBATCH --job-name=vesuvius60
#SBATCH --output=logs/train_60epoch_%j.out
#SBATCH --error=logs/train_60epoch_%j.err

echo "Starting 60-epoch training on A100"
echo "Node: $SLURM_NODELIST"
nvidia-smi

cd /scratch/jowny/vesuvius/vesuviusChallenge/vesuvius-competition
export PYTHONPATH=$PWD:$PWD/src
source venv/bin/activate

python train.py --config configs/experiments/surface_unet3d_tuned.yaml
EOF

mkdir -p logs
sbatch train_60epoch.sbatch

# To monitor the job:
squeue -u jowny

# To check logs:
# tail -f logs/train_60epoch_*.out